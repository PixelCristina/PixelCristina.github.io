---
title: "Assignment7"
code-fold: true
---

```{r}
# Knowledge Mining: Logistic Regression
# File: Lab_logisticregression01.R
# Theme: Logistic regression
# Adapted from ISLR Chapter 4 Lab

# Load ISLR library

require(ISLR)

# Check dataset Smarket
?Smarket
names(Smarket)
summary(Smarket)

# Create a dataframe for data browsing
sm=Smarket

# Bivariate Plot of inter-lag correlations
pairs(Smarket,col=Smarket$Direction,cex=.5, pch=20)

# Logistic regression
glm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,
            data=Smarket,family=binomial)
summary(glm.fit)
glm.probs=predict(glm.fit,type="response") 
glm.probs[1:5]
glm.pred=ifelse(glm.probs>0.5,"Up","Down")
attach(Smarket)
table(glm.pred,Direction)
mean(glm.pred==Direction)
```

```{r}
# Make training and test set for prediction
train = Year<2005
glm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,
            data=Smarket,family=binomial, subset=train)
glm.probs=predict(glm.fit,newdata=Smarket[!train,],type="response") 
glm.pred=ifelse(glm.probs >0.5,"Up","Down")
Direction.2005=Smarket$Direction[!train]
table(glm.pred,Direction.2005)
mean(glm.pred==Direction.2005)
```

```{r}
#Fit smaller model
glm.fit=glm(Direction~Lag1+Lag2,
            data=Smarket,family=binomial, subset=train)
glm.probs=predict(glm.fit,newdata=Smarket[!train,],type="response") 
glm.pred=ifelse(glm.probs >0.5,"Up","Down")
table(glm.pred,Direction.2005)
mean(glm.pred==Direction.2005)
```

```{r}
# Check accuracy rate
106/(76+106)
```

a\. **LDA Requirements**: Assumes normal distribution of predictors and equal covariance across all classes.

b\. **Differences between LDA and Logistic Regression**: LDA assumes a common covariance matrix and normally distributed predictors, which is efficient when true. Logistic regression doesn't assume normality and works well with non-linear class boundaries.

c\. **ROC (Receiver Operating Characteristic)**: A plot that shows the performance of a classifier at various thresholds by plotting the true positive rate against the false positive rate. The area under the curve (AUC) indicates the model's ability to differentiate classes.

d\. **Sensitivity and Specificity**:

-   **Sensitivity**: The ability to correctly identify actual positives.

-   **Specificity**: The ability to correctly identify actual negatives.
    The importance of each depends on the specific application, e.g., sensitivity is crucial in medical diagnostics to not miss any cases of disease.

e\. **Classification Metrics**: The critical metric for prediction depends on the consequences of false positives and false negatives, varying by context like healthcare or finance.

This summary provides a clear overview of the topics covered in Chapter 4, highlighting the theoretical differences and practical implications of different classification methods.

```{r}

```
